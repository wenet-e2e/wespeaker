### train configuraton

exp_dir: exp/resnet34
gpus: "[0]"
num_avg: 10
enable_amp: False # whether enable automatic mixed precision training

### dataset setting
data_type: shard

# train_data: /home/yifa/xiyang/wespeaker/dataset/train/wav.scp
# train_label: /home/yifa/xiyang/wespeaker/dataset/train/utt2spk

# cv_data: /home/yifa/xiyang/wespeaker/dataset/dev/wav.scp
# cv_label: /home/yifa/xiyang/wespeaker/dataset/dev/utt2spk

data_type: 'raw'
train_data: 'dataset/train.list'   # The JSON manifest we created
train_label: 'dataset/train_utt2spk' # The complete mapping of utterance to speaker
cv_data: 'dataset/dev.list'       # The validation JSON manifest
cv_label: 'dataset/dev_utt2spk'   # The validation label mapping


seed: 42
num_epochs: 10
save_epoch_interval: 1 # save model every 5 epochs
log_batch_interval: 100 # log every 100 batchs

dataloader_args:
  batch_size: 64
  num_workers: 16
  pin_memory: False
  prefetch_factor: 8
  drop_last: True

dataset_args:
  # the sample number which will be traversed within one epoch, if the value equals to 0,
  # the utterance number in the dataset will be used as the sample_num_per_epoch.
  sample_num_per_epoch: 0
  shuffle: True
  shuffle_args:
    shuffle_size: 2500
  filter: True
  filter_args:
    min_num_frames: 100
    max_num_frames: 800
  resample_rate: 16000
  speed_perturb: True
  num_frms: 200
  aug_prob: 0.6 # prob to add reverb & noise aug per sample
  fbank_args:
    num_mel_bins: 80
    frame_shift: 10
    frame_length: 25
    dither: 1.0
  spec_aug: False
  spec_aug_args:
    num_t_mask: 1
    num_f_mask: 1
    max_t: 10
    max_f: 8
    prob: 0.6

model: ResNet34 # ResNet18, ResNet34, ResNet50, ResNet101, ResNet152
model_init: /home/yifa/xiyang/wespeaker/voxceleb_resnet34/avg_model.pt
model_args:
  feat_dim: 80
  embed_dim: 256
  pooling_func: "TSTP" # TSTP, ASTP, MQMHASTP
  two_emb_layer: False
projection_args:
  project_type: "arc_margin" # add_margin, arc_margin, sphere, sphereface2, softmax, arc_margin_intertopk_subcenter
  scale: 32.0
  easy_margin: False
  num_class: 8

margin_scheduler: MarginScheduler
margin_update:
  initial_margin: 0.0
  final_margin: 0.2
  increase_start_epoch: 20
  fix_start_epoch: 40
  update_margin: True
  increase_type: "exp" # exp, linear

loss: CrossEntropyLoss
loss_args: {}

optimizer: SGD
optimizer_args:
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001

scheduler: ExponentialDecrease
scheduler_args:
  initial_lr: 0.01
  final_lr: 0.00005
  warm_up_epoch: 6
  warm_from_zero: True
